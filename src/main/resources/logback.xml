<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    <property scope="context" name="service_name" value="api-gateway"/>
    <property name="LOG_FILE" value="logs/${service_name}.log"/>â€‹
    <property name="CONSOLE_LOG_PATTERN"
              value="%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr([${service_name:-},%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-Span-Export:-}]){yellow} %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <!--<filter class="ch.qos.logback.classic.filter.ThresholdFilter">-->
            <!--&lt;!&ndash; Minimum logging level to be presented in the console logs&ndash;&gt;-->
            <!--<level>DEBUG</level>-->
        <!--</filter>-->
        <!--<encoder>-->
            <!--<pattern>${CONSOLE_LOG_PATTERN}</pattern>-->
        <!--</encoder>-->
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>
    <appender name="TIME_BASED_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_FILE}</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy">
            <fileNamePattern>${LOG_FILE}.%i.log.zip</fileNamePattern>
            <minIndex>1</minIndex>
            <maxIndex>13</maxIndex>
        </rollingPolicy>
        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <maxFileSize>20MB</maxFileSize>
        </triggeringPolicy>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>

    <!--&lt;!&ndash; This is the kafkaAppender &ndash;&gt;-->
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
        <topic>${service_name}-logs</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />

        <!-- Optional parameter to use a fixed partition -->
         <!--<partition>0</partition>-->

        <!-- Optional parameter to include log timestamps into the kafka message -->
        <!-- <appendTimestamp>true</appendTimestamp> -->

        <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
        <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
        <!-- bootstrap.servers is the only mandatory producerConfig -->
        <producerConfig>bootstrap.servers=172.26.40.211:9092, 172.26.40.212:9092, 172.26.40.213:9092</producerConfig>

        <!-- this is the fallback appender if kafka is not available. -->
        <appender-ref ref="TIME_BASED_FILE" />
    </appender>

    <logger name="org.apache.kafka" level="WARN" />
    <logger name="org.springframework.cloud.gateway" level="TRACE"/>
    <logger name="org.springframework.http.server.reactive" level="DEBUG"/>
    <logger name="org.springframework.web.reactive" level="DEBUG"/>
    <logger name="reactor.ipc.netty" level="DEBUG"/>
    <logger name="reactor.netty" level="DEBUG"/>

    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="kafkaAppender" />
    </root>
</configuration>